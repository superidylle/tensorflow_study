{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta0\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import datasets, layers, optimizers\n",
    "import  os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (60000, 28, 28) y: (60000, 10)\n",
      "sample: (128, 28, 28) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "(x, y), _ = datasets.mnist.load_data()\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 50.\n",
    "y = tf.convert_to_tensor(y)\n",
    "y = tf.one_hot(y, depth=10)\n",
    "print('x:', x.shape, 'y:', y.shape)\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128).repeat(30)\n",
    "x,y = next(iter(train_db))\n",
    "print('sample:', x.shape, y.shape)\n",
    "# print(x[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # 784 => 512\n",
    "    w1, b1 = tf.Variable(tf.random.truncated_normal([784, 512], stddev=0.1)), tf.Variable(tf.zeros([512]))\n",
    "    # 512 => 256\n",
    "    w2, b2 = tf.Variable(tf.random.truncated_normal([512, 256], stddev=0.1)), tf.Variable(tf.zeros([256]))\n",
    "    # 256 => 10\n",
    "    w3, b3 = tf.Variable(tf.random.truncated_normal([256, 10], stddev=0.1)), tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\n",
    "\n",
    "    optimizer = optimizers.SGD(lr=0.01)\n",
    "\n",
    "\n",
    "    for step, (x,y) in enumerate(train_db):\n",
    "\n",
    "        # [b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, (-1, 784))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # layer1.\n",
    "            h1 = x @ w1 + b1\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            # layer2\n",
    "            h2 = h1 @ w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            # output\n",
    "            out = h2 @ w3 + b3\n",
    "            # out = tf.nn.relu(out)\n",
    "\n",
    "            # compute loss\n",
    "            # [b, 10] - [b, 10]\n",
    "            loss = tf.square(y-out)\n",
    "            # [b, 10] => [b]\n",
    "            loss = tf.reduce_mean(loss, axis=1)\n",
    "            # [b] => scalar\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "\n",
    "        # compute gradient\n",
    "        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "#         print('==before==')\n",
    "#         for g in grads:\n",
    "#             print(tf.norm(g))\n",
    "        \n",
    "        grads,  _ = tf.clip_by_global_norm(grads, 15)\n",
    "\n",
    "#         print('==after==')\n",
    "#         for g in grads:\n",
    "#             print(tf.norm(g))\n",
    "        # update w' = w - lr*grad\n",
    "        optimizer.apply_gradients(zip(grads, [w1, b1, w2, b2, w3, b3]))\n",
    "\n",
    "\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, 'loss:', float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0712 17:13:10.021475 10532 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 18.022930145263672\n",
      "100 loss: 0.5609304904937744\n",
      "200 loss: 0.19347219169139862\n",
      "300 loss: 0.11454254388809204\n",
      "400 loss: 0.09388627856969833\n",
      "500 loss: 0.08335365355014801\n",
      "600 loss: 0.09147751331329346\n",
      "700 loss: 0.07416548579931259\n",
      "800 loss: 0.07457949221134186\n",
      "900 loss: 0.05971747264266014\n",
      "1000 loss: 0.06924252212047577\n",
      "1100 loss: 0.061092816293239594\n",
      "1200 loss: 0.06249769404530525\n",
      "1300 loss: 0.06767154484987259\n",
      "1400 loss: 0.03836298733949661\n",
      "1500 loss: 0.05026475340127945\n",
      "1600 loss: 0.056450698524713516\n",
      "1700 loss: 0.05627186596393585\n",
      "1800 loss: 0.05868540704250336\n",
      "1900 loss: 0.048836737871170044\n",
      "2000 loss: 0.04968646541237831\n",
      "2100 loss: 0.04940018057823181\n",
      "2200 loss: 0.04874312877655029\n",
      "2300 loss: 0.03752657771110535\n",
      "2400 loss: 0.04205044358968735\n",
      "2500 loss: 0.048552799969911575\n",
      "2600 loss: 0.04604307562112808\n",
      "2700 loss: 0.04474641755223274\n",
      "2800 loss: 0.0314779207110405\n",
      "2900 loss: 0.03117663413286209\n",
      "3000 loss: 0.04249615967273712\n",
      "3100 loss: 0.03164031356573105\n",
      "3200 loss: 0.0481623038649559\n",
      "3300 loss: 0.03633440285921097\n",
      "3400 loss: 0.030606897547841072\n",
      "3500 loss: 0.040630798786878586\n",
      "3600 loss: 0.03759925067424774\n",
      "3700 loss: 0.03622179850935936\n",
      "3800 loss: 0.03345780074596405\n",
      "3900 loss: 0.038294874131679535\n",
      "4000 loss: 0.04099831357598305\n",
      "4100 loss: 0.029308199882507324\n",
      "4200 loss: 0.02743689715862274\n",
      "4300 loss: 0.03392253443598747\n",
      "4400 loss: 0.028968388214707375\n",
      "4500 loss: 0.031295545399188995\n",
      "4600 loss: 0.03268738090991974\n",
      "4700 loss: 0.03409494459629059\n",
      "4800 loss: 0.03668895363807678\n",
      "4900 loss: 0.02892257645726204\n",
      "5000 loss: 0.03903063386678696\n",
      "5100 loss: 0.023702893406152725\n",
      "5200 loss: 0.027340082451701164\n",
      "5300 loss: 0.025900721549987793\n",
      "5400 loss: 0.03706859052181244\n",
      "5500 loss: 0.02737768366932869\n",
      "5600 loss: 0.03399123251438141\n",
      "5700 loss: 0.03178158774971962\n",
      "5800 loss: 0.0348980613052845\n",
      "5900 loss: 0.0360599085688591\n",
      "6000 loss: 0.03052779659628868\n",
      "6100 loss: 0.027982883155345917\n",
      "6200 loss: 0.029321616515517235\n",
      "6300 loss: 0.026283182203769684\n",
      "6400 loss: 0.02166801691055298\n",
      "6500 loss: 0.023782160133123398\n",
      "6600 loss: 0.02517918311059475\n",
      "6700 loss: 0.033769845962524414\n",
      "6800 loss: 0.03301909938454628\n",
      "6900 loss: 0.027820128947496414\n",
      "7000 loss: 0.024754531681537628\n",
      "7100 loss: 0.028014974668622017\n",
      "7200 loss: 0.023653434589505196\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-38741680b83a>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;31m# [b, 10] => [b]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[1;31m# [b] => scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_mean\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   1762\u001b[0m       gen_math_ops.mean(\n\u001b[0;32m   1763\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1764\u001b[1;33m           name=name))\n\u001b[0m\u001b[0;32m   1765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[0;32m   6537\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mean\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6538\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"keep_dims\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6539\u001b[1;33m         keep_dims)\n\u001b[0m\u001b[0;32m   6540\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6541\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
